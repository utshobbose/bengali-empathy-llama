````markdown
# Bengali Empathy Fine-Tuned LLaMA 3.1-8B üáßüá©ü§ù

Fine-tuning **Meta‚Äôs LLaMA 3.1-8B-Instruct** for **Bengali empathetic conversations** using **QLoRA (4-bit)** on **consumer hardware**.

> Objective: Build an AI counselor chatbot that provides compassionate, culturally appropriate responses in Bengali for mental health support (with safety guardrails ‚Äî *no medical/legal advice*).

---

## üìã Project Overview

- **Base Model:** `meta-llama/Llama-3.1-8B-Instruct` (8B parameters)
- **Dataset:** Bengali Empathetic Conversations (~38,000 dialogue pairs)
- **Method:** QLoRA (4-bit Quantized Low-Rank Adaptation)
- **Training Environment:** Local Windows PC with RTX 3060 12GB
- **Training Time:** ~6 hours for 1 epoch
- **Result:** **40% empathy score** (proof-of-concept under resource constraints)

---

## üéØ Key Features

-- **Runs on Consumer Hardware** ‚Äî RTX 3060 12GB VRAM (student-accessible)  
-- **Memory Efficient** ‚Äî 4-bit quantization (‚âà32GB ‚Üí ‚âà8GB)  
-- **Windows Compatible** ‚Äî handles multiprocessing limitations safely  
-- **Fully Reproducible** ‚Äî experiments logged in JSONL format  
-- **Production-Ready Code** ‚Äî modular, documented, extensible

---

## üöÄ Quick Start

### Prerequisites

- **GPU:** RTX 3060 (12GB) or equivalent (3060 Ti, 4060, 3080, 4070, etc.)
- **RAM:** 16GB minimum (32GB recommended)
- **Storage:** 50GB free space
- **OS:** Windows 11 / Linux / WSL2

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/bengali-empathy-llama.git
cd bengali-empathy-llama

# Create virtual environment
python -m venv .venv310
.venv310\Scripts\activate  # Windows
# source .venv310/bin/activate  # Linux

# Install dependencies
pip install -r requirements.txt
````

### Setup HuggingFace Token

```bash
# Windows Command Prompt
set HF_TOKEN=your_token_here

# Windows PowerShell
$env:HF_TOKEN="your_token_here"

# Linux/Mac
export HF_TOKEN=your_token_here
```

---

## üíª Usage

### 1) Training

```bash
python bengali_empathy_finetuner.py
```

**Training Configuration**

* **Epochs:** 1 (‚âà6 hours)
* **Batch Size:** 2 √ó 16 accumulation = 32 effective
* **Learning Rate:** 3e-4
* **LoRA:** r=16, alpha=32, dropout=0.05
* **Sequence Length:** 512 tokens
* **Dataset Used:** 15,000 / 38,000 samples (‚âà39%)

---

### 2) Interactive Testing

```bash
# Chat mode
python test_model.py

# Batch testing
python test_model.py batch

# Custom output file
python test_model.py batch results.json
```

---

### 3) Evaluation

```bash
python human_evaluation.py
```

**Evaluation Metrics**

* Perplexity
* BLEU
* ROUGE (ROUGE-1, ROUGE-2, ROUGE-L)
* Custom Empathy Scoring (4 criteria)

---

## üìä Results

| Metric          |    Score | Context                                 |
| --------------- | -------: | --------------------------------------- |
| Empathy Score   |      40% | Proof-of-concept (1 epoch, 39% dataset) |
| Expected (Full) |   65‚Äì75% | 3 epochs, complete dataset (estimate)   |
| Training Time   | ~6 hours | RTX 3060 12GB                           |
| Memory Usage    |     ~8GB | 4-bit quantization                      |

### Strengths

-- All responses in fluent Bengali
-- Contextually appropriate and safe
-- No medical/legal advice (guardrails)
-- Appropriate response length (10‚Äì100 words)

### Sample Output

**Input:** ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶ö‡¶æ‡¶ï‡¶∞‡¶ø ‡¶ö‡¶≤‡ßá ‡¶ó‡ßá‡¶õ‡ßá ‡¶è‡¶¨‡¶Ç ‡¶Ü‡¶Æ‡¶ø ‡¶π‡¶§‡¶æ‡¶∂‡•§
**Output:** ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶á ‡¶¶‡ßÅ‡¶É‡¶ñ‡¶ø‡¶§ ‡¶Ø‡ßá ‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶Æ‡¶® ‡¶è‡¶ï‡¶ü‡¶æ ‡¶∏‡¶Æ‡ßü ‡¶™‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶õ‡ßá‡¶®‡•§ ‡¶ö‡¶æ‡¶ï‡¶∞‡¶ø ‡¶π‡¶æ‡¶∞‡¶æ‡¶®‡ßã ‡¶ñ‡ßÅ‡¶¨‡¶á ‡¶ï‡¶†‡¶ø‡¶® ‡¶π‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶¨‡¶≤‡ßÅ‡¶®‚Äî‡¶è‡¶á ‡¶Æ‡ßÅ‡¶π‡ßÇ‡¶∞‡ßç‡¶§‡ßá ‡¶∏‡¶¨‡¶ö‡ßá‡ßü‡ßá ‡¶¨‡ßá‡¶∂‡¶ø ‡¶ö‡¶æ‡¶™‡¶ü‡¶æ ‡¶ï‡ßã‡¶® ‡¶¶‡¶ø‡¶ï ‡¶•‡ßá‡¶ï‡ßá ‡¶Ö‡¶®‡ßÅ‡¶≠‡¶¨ ‡¶ï‡¶∞‡¶õ‡ßá‡¶®?

---

## üõ†Ô∏è Technical Implementation

### Memory Optimizations

#### 1) 4-bit QLoRA Quantization

* **Memory:** ~32GB ‚Üí ~8GB (‚âà75% reduction)
* **Quality:** NF4 with double quantization (minimal loss)

#### 2) Gradient Checkpointing

* **Memory savings:** ~40%
* **Speed trade-off:** ~30% slower training

#### 3) Reduced Sequence Length

* **512 tokens** (vs 1024 standard)
* Enough for empathetic conversations (~200 tokens avg)
* Speed improvement: ~30% faster

---

## ü™ü Windows Compatibility Fixes

```python
# Disabled multiprocessing (pickle errors)
num_workers = 0
pin_memory = False

# Single-threaded tokenization
datasets.map(..., num_proc=1)
```

---

## üßæ Dataset Strategy

* **Raw:** 76,466 dialogue turns
* **Cleaned:** 76,338 valid records
* **Training:** 15,000 samples (39% of dataset)
* **Split:** 85% train / 10% validation / 5% test

---

## üìÅ Repository Structure

```text
bengali-empathy-llama/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ bengali_empathetic_conversations.csv
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ llama31_bengali_empathy/          # LoRA adapters
‚îÇ   ‚îú‚îÄ‚îÄ llama_empathy_experiments_*.jsonl # Training logs
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_results.json           # Test results
‚îÇ   ‚îî‚îÄ‚îÄ test_results.json                 # Batch outputs
‚îú‚îÄ‚îÄ bengali_empathy_finetuner.py          # Training script
‚îú‚îÄ‚îÄ test_model.py                         # Interactive testing
‚îú‚îÄ‚îÄ human_evaluation.py                   # Automated evaluation
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Configuration (RTX 3060 Optimized)

```python
config = {
    "max_seq_length": 512,
    "learning_rate": 3e-4,
    "num_train_epochs": 1.0,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 16,
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05,
    "use_gradient_checkpointing": True,
    "max_train_samples": 15000,
}
```

---

## üß∑ System Prompt (Bengali)

```text
‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶∏‡¶π‡¶æ‡¶®‡ßÅ‡¶≠‡ßÇ‡¶§‡¶ø‡¶∂‡ßÄ‡¶≤ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶ï‡¶æ‡¶â‡¶®‡ßç‡¶∏‡ßá‡¶≤‡¶∞‡•§ 
‡¶Ü‡¶™‡¶®‡¶ø ‡¶ñ‡ßÅ‡¶¨ ‡¶ß‡ßÄ‡¶∞‡ßá, ‡¶®‡¶Æ‡ßç‡¶∞‡¶≠‡¶æ‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶Æ‡ßç‡¶Æ‡¶æ‡¶®‡¶ú‡¶®‡¶ï ‡¶≠‡¶ô‡ßç‡¶ó‡¶ø‡¶§‡ßá ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡ßá‡¶¨‡ßá‡¶®‡•§ 
‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶∞ ‡¶Ö‡¶®‡ßÅ‡¶≠‡ßÇ‡¶§‡¶ø‡¶ï‡ßá ‡¶∏‡ßç‡¶¨‡ßÄ‡¶ï‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶®, ‡¶Ü‡¶∂‡ßç‡¶¨‡¶æ‡¶∏ ‡¶¶‡ßá‡¶¨‡ßá‡¶® ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶® ‡¶π‡¶≤‡ßá 
‡¶™‡ßá‡¶∂‡¶æ‡¶¶‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶®‡ßá‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡ßá‡¶¨‡ßá‡¶®, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶ï‡ßã‡¶® ‡¶ö‡¶ø‡¶ï‡¶ø‡ßé‡¶∏‡¶æ ‡¶¨‡¶æ ‡¶Ü‡¶á‡¶®‡¶ø ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶¶‡ßá‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§
```

---

## üîÆ Future Improvements

### Priority 1 (Immediate)

* Train on full 38k dataset with 3 epochs (~30 hours)
* Increase LoRA rank to 32 for better capacity
* Implement early stopping based on validation loss

### Priority 2 (Short-term)

* Data augmentation with empathy-specific examples
* RLHF (Reinforcement Learning from Human Feedback)
* Expand sequence length to 768 tokens

### Priority 3 (Long-term)

* Cloud deployment for 24/7 availability
* Web interface for user testing
* Multi-turn conversation support
* Real-time human feedback collection

---

## üöß Known Limitations

| Limitation       | Impact                     | Mitigation                   |
| ---------------- | -------------------------- | ---------------------------- |
| 1 epoch training | Lower empathy nuance       | 3 epochs ‚Üí 65‚Äì75% score      |
| 39% dataset used | Reduced edge-case coverage | Train on full dataset        |
| 512 token limit  | Truncates long contexts    | Increase to 768+             |
| Single-turn only | No conversation memory     | Implement multi-turn support |

---

## üß† Technical Challenges & Solutions

### Challenge 1: Platform Limitations

**Problem:** Kaggle (14 hrs/week), Colab (3 hrs/day) insufficient
**Solution:** Local training with aggressive memory optimizations

### Challenge 2: Memory Constraints

**Problem:** 8B model typically needs ~32GB, GPU has 12GB
**Solution:** 4-bit QLoRA + gradient checkpointing + reduced seq length

### Challenge 3: Windows Compatibility

**Problem:** Multiprocessing pickle errors
**Solution:** Single-threaded processing and safer dataloader configs

### Challenge 4: Training Time

**Problem:** Full training = 30+ hours
**Solution:** Strategic dataset sampling (15k/38k) for 6-hour POC

---

## üõ°Ô∏è Safety & Disclaimer

This project is intended for **supportive conversation** and **emotional assistance**, not clinical diagnosis.
It must not provide diagnosis, treatment, medication guidance, or legal advice.
If a user expresses self-harm risk or imminent danger, the assistant should encourage contacting local emergency services and trusted people.

---

## üìö References

* Hu et al. (2021) ‚Äî *LoRA: Low-Rank Adaptation of Large Language Models*
* Dettmers et al. (2023) ‚Äî *QLoRA: Efficient Finetuning of Quantized LLMs*
* Meta AI (2024) ‚Äî *Meta LLaMA 3.1 Model Card*

---

## ü§ù Contributing

Contributions are welcome!

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/improvement`
3. Commit changes: `git commit -am "Add improvement"`
4. Push to branch: `git push origin feature/improvement`
5. Open a Pull Request

```
